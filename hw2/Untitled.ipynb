{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load the Microsoft.com data into HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "delete data folder and re-create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/18 18:43:07 INFO fs.TrashPolicyDefault: Moved: 'hdfs://bdl0.eng.tau.ac.il:8020/user/stud22/ex2' to trash at: hdfs://bdl0.eng.tau.ac.il:8020/user/stud22/.Trash/Current/user/stud22/ex21652888587384\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -rm -r /user/stud22/ex2\n",
    "hdfs dfs -mkdir /user/stud22/ex2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put data and then show contents of folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 stud22 stud22        387 2022-05-18 18:43 /user/stud22/ex2/countries.txt\n",
      "-rw-r--r--   3 stud22 stud22    1491520 2022-05-18 18:43 /user/stud22/ex2/microsoft-com.data\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -put /home/stud22/workspace/ex2/microsoft-com.data/microsoft-com.data /user/stud22/ex2/microsoft-com.data\n",
    "hdfs dfs -put /home/stud22/workspace/ex2/microsoft-com.data/countries.txt /user/stud22/ex2/countries.txt\n",
    "hdfs dfs -ls /user/stud22/ex2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show last lines of data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V,42709,1003,1\n",
      "V,42710,1035,1\n",
      "V,42710,1001,1\n",
      "V,42710,1018,1\n",
      "V,42711,1008,1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -cat /user/stud22/ex2/microsoft-com.data | tail -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Parse the data according to the format specified in the .info file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'V', u'42711', u'1008', u'1'],\n",
       " [u'V', u'42710', u'1035', u'1'],\n",
       " [u'V', u'42710', u'1018', u'1'],\n",
       " [u'V', u'42710', u'1001', u'1'],\n",
       " [u'V', u'42709', u'1003', u'1']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rdd = sc.textFile(\"hdfs:/user/stud22/ex2/microsoft-com.data\") # read data\n",
    "lst_rdd = raw_rdd.map(lambda line: line.replace('\"','').split(',')) # split each row by ,\n",
    "lst_rdd.top(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) only users that visited at least one page related to one of the given countries.\n",
    "Given the list of countries in the file countries.txt (e.g., South Africa, Spain, Sweden, Switzerland), filter the data to include only users that visited at least one page related to one of the given countries.\n",
    "\n",
    "**ASSUMPTION: the header is the same as the country name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_votes_by_countries(attr_rdd,votes_rdd,countries_rdd):\n",
    "    # return votes for attributes which contains country name\n",
    "    countries_lst = sc.broadcast(countries_rdd.collect()) # broadcast countries between nodes\n",
    "    relevant_lines = attr_rdd.filter(lambda x: x[3] in countries_lst.value) # filter attribute lines which contains countries\n",
    "    relevant_ids = relevant_lines.map(lambda x: x[1]) # get ids of relevant attribute line (which contains country)\n",
    "    country_ids = sc.broadcast(relevant_ids.collect()) # TODO: verify that we don't cheat!! (might be lots of records)\n",
    "    country_votes = votes_rdd.filter(lambda x: x[2] in country_ids.value) # return the votes\n",
    "    return country_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attr_rdd = lst_rdd.filter(lambda x: x[0]=='A') # filter attribute lines\n",
    "votes_rdd = lst_rdd.filter(lambda x: x[0]=='V') # filter votes lines\n",
    "countries_rdd = sc.textFile(\"hdfs:/user/stud22/ex2/countries.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'A', u'1297', u'1', u'Central America', u'/centroam'],\n",
       " [u'A', u'1295', u'1', u'Training', u'/train_cert'],\n",
       " [u'A', u'1294', u'1', u'Bookshelf', u'/bookshelf']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_rdd.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'V', u'42711', u'1008', u'1'],\n",
       " [u'V', u'42710', u'1035', u'1'],\n",
       " [u'V', u'42710', u'1018', u'1']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes_rdd.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Venezuela', u'Uruguay', u'UK']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_rdd.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_votes = filter_votes_by_countries(attr_rdd,votes_rdd,countries_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'V', u'42708', u'1123', u'1'],\n",
       " [u'V', u'42706', u'1059', u'1'],\n",
       " [u'V', u'42698', u'1005', u'1'],\n",
       " [u'V', u'42688', u'1053', u'1'],\n",
       " [u'V', u'42665', u'1023', u'1'],\n",
       " [u'V', u'42649', u'1223', u'1'],\n",
       " [u'V', u'42647', u'1023', u'1'],\n",
       " [u'V', u'42641', u'1053', u'1'],\n",
       " [u'V', u'42637', u'1053', u'1'],\n",
       " [u'V', u'42636', u'1053', u'1']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_votes.top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relevant_users = country_votes.map(lambda x: x[1]).distinct() # drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'42708',\n",
       " u'42706',\n",
       " u'42698',\n",
       " u'42688',\n",
       " u'42665',\n",
       " u'42649',\n",
       " u'42647',\n",
       " u'42641',\n",
       " u'42637',\n",
       " u'42636']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_users.top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of relevant users: 3199, number of relevant votes: 3334\n"
     ]
    }
   ],
   "source": [
    "print(\"number of relevant users: %s, number of relevant votes: %s\"%(relevant_users.count(),country_votes.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter votes by the user ids we have found \n",
    "user_ids = sc.broadcast(relevant_users.collect()) \n",
    "relevant_data = votes_rdd.filter(lambda x: x[1] in user_ids.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'V', u'42708', u'1123', u'1'],\n",
       " [u'V', u'42708', u'1041', u'1'],\n",
       " [u'V', u'42708', u'1038', u'1'],\n",
       " [u'V', u'42708', u'1027', u'1'],\n",
       " [u'V', u'42708', u'1026', u'1']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_data.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.b) For each country, the number of users that visited a page of that country\n",
    "For each country, the number of users that visited a page of that country. Exclude from your\n",
    "report countries with a name longer than one word.\n",
    "\n",
    "**ASSUMPTION: country names are splitted only by spaces**\n",
    "\n",
    "**ASSUMPTION: titles are unique (validated on the last block)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_word_countries = countries_rdd.filter(lambda x: len(x.split(\" \")) < 2) # get only one-word countries\n",
    "one_word_lst = one_word_countries.collect() # small, constant size list - so it's fine to collect\n",
    "country_name_mapping = dict(attr_rdd.filter(lambda x: x[3] in one_word_lst) \\\n",
    ".map(lambda x: (x[1],x[3])).collect()) # dict of attribute line id -> country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'1227': u'Argentina', u'1165': u'Poland', u'1166': u'Mexico', u'1084': u'UK', u'1223': u'Finland', u'1208': u'Israel', u'1080': u'Brazil', u'1262': u'Chile', u'1123': u'Germany', u'1267': u'Caribbean', u'1203': u'Denmark', u'1073': u'Taiwan', u'1209': u'Turkey', u'1217': u'Ireland', u'1053': u'Jakarta', u'1079': u'Australia', u'1059': u'Sweden', u'1195': u'Portugal', u'1194': u'China', u'1107': u'Slovakia', u'1112': u'Canada', u'1115': u'Hungary', u'1116': u'Switzerland', u'1258': u'Peru', u'1172': u'Belgium', u'1179': u'Colombia', u'1152': u'Russia', u'1229': u'Uruguay', u'1153': u'Venezuela', u'1188': u'Korea', u'1023': u'Spain', u'1183': u'Italy', u'1180': u'Slovenija', u'1241': u'India', u'1240': u'Thailand', u'1105': u'France', u'1005': u'Norway'}\n"
     ]
    }
   ],
   "source": [
    "print(country_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_votes_one = filter_votes_by_countries(attr_rdd,votes_rdd,one_word_countries) # relevant vote lines for one word countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'42708', u'1123'],\n",
       " [u'42706', u'1059'],\n",
       " [u'42698', u'1005'],\n",
       " [u'42688', u'1053'],\n",
       " [u'42665', u'1023']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid_vid = country_votes_one.map(lambda x: x[1:3]) # user id and attribute line id\n",
    "uid_vid.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'42708', u'Germany'),\n",
       " (u'42706', u'Sweden'),\n",
       " (u'42698', u'Norway'),\n",
       " (u'42688', u'Jakarta'),\n",
       " (u'42665', u'Spain')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid_country = uid_vid.map(lambda x: (x[0], country_name_mapping[x[1]])) # use the dict we created to get country name\n",
    "uid_country.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uid_country_unique = uid_country.distinct() # count only once each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Brazil', 121),\n",
       " (u'Canada', 128),\n",
       " (u'Italy', 167),\n",
       " (u'Peru', 3),\n",
       " (u'France', 183),\n",
       " (u'Slovakia', 11),\n",
       " (u'Ireland', 13),\n",
       " (u'Caribbean', 5),\n",
       " (u'Argentina', 32),\n",
       " (u'Venezuela', 8),\n",
       " (u'Israel', 34),\n",
       " (u'Korea', 94),\n",
       " (u'Norway', 42),\n",
       " (u'Germany', 372),\n",
       " (u'Chile', 4),\n",
       " (u'Denmark', 55),\n",
       " (u'Belgium', 45),\n",
       " (u'Thailand', 11),\n",
       " (u'Poland', 38),\n",
       " (u'Spain', 191),\n",
       " (u'UK', 186),\n",
       " (u'Jakarta', 670),\n",
       " (u'Turkey', 9),\n",
       " (u'Finland', 29),\n",
       " (u'Sweden', 258),\n",
       " (u'Australia', 136),\n",
       " (u'Switzerland', 31),\n",
       " (u'Russia', 52),\n",
       " (u'Portugal', 15),\n",
       " (u'Mexico', 33),\n",
       " (u'Uruguay', 4),\n",
       " (u'India', 9),\n",
       " (u'China', 26),\n",
       " (u'Colombia', 11),\n",
       " (u'Hungary', 15),\n",
       " (u'Taiwan', 204),\n",
       " (u'Slovenija', 9)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = uid_country_unique.map(lambda x: x[1])\n",
    "sum_by_country = countries.countByValue()\n",
    "sum_by_country.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.c) The top 5 visited countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_votes = filter_votes_by_countries(attr_rdd,votes_rdd,countries_rdd)\n",
    "country_votes_ids = country_votes.map(lambda x: x[2])\n",
    "votes_count = country_votes_ids.countByValue() # returns a python dict - it's fine, because we deal with small dict\n",
    "top_5_votes_count = sorted(votes_count.items(), key=lambda x:x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 visited countries:\n",
      "1. Jakarta: 670\n",
      "2. Germany: 372\n",
      "3. Sweden: 258\n",
      "4. Taiwan: 204\n",
      "5. Spain: 191\n"
     ]
    }
   ],
   "source": [
    "print(\"The top 5 visited countries:\")\n",
    "for i in range(5):\n",
    "    country_id, cnt = top_5_votes_count[i]\n",
    "    print(\"%s. %s: %s\"%(i+1,country_name_mapping[country_id],cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Write the report (4.a) to HDFS for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: based on 4.a which we skipped...\n",
    "uid_vid.saveAsTextFile(\"hdfs:/user/stud22/ex2/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   3 stud22 stud22          0 2022-05-18 18:43 /user/stud22/ex2/output/_SUCCESS\n",
      "-rw-r--r--   3 stud22 stud22      33160 2022-05-18 18:43 /user/stud22/ex2/output/part-00000\n",
      "-rw-r--r--   3 stud22 stud22      31920 2022-05-18 18:43 /user/stud22/ex2/output/part-00001\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -ls /user/stud22/ex2/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *verify that titles are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of country titels: 41\n",
      "number of distinct country titels: 41\n",
      "they are equal - so the assumption that the titles are unique holds...\n"
     ]
    }
   ],
   "source": [
    "countries_rdd = sc.textFile(\"hdfs:/user/stud22/ex2/countries.txt\")\n",
    "countries_lst = sc.broadcast(countries_rdd.collect())\n",
    "tmp  = attr_rdd.filter(lambda x: x[3] in countries_lst.value).map(lambda x: x[3])\n",
    "print(\"number of country titels: %s\"%(tmp.count()))\n",
    "print(\"number of distinct country titels: %s\"%(tmp.distinct().count()))\n",
    "assert(tmp.count() == tmp.distinct().count())\n",
    "print(\"they are equal - so the assumption that the titles are unique holds...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark2(2.1.0)",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
