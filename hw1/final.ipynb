{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "functions for connecting and setting up the databases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_env = 'production' # 'docker' for development on docker, 'production' for real server\n",
    "current_user = 'stud10'\n",
    "ENV = {\"docker\": '172.17.0.1',\"production\":'bdl1.eng.tau.ac.il'}\n",
    "companiesSet = current_user+\":company:names\"\n",
    "ojOSet = current_user+\":oj\"\n",
    "cand_app_set = current_user+\":candidate_application\"\n",
    "redis_db_num = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_redis(db,port=6379):\n",
    "    # We connect to redis on a specific database (db_num) to not interuprt other students\n",
    "    r = redis.StrictRedis(host=ENV[current_env], port=port, socket_connect_timeout=10,db=db_num)\n",
    "    r.ping() # send ping to verify that a connection established to redis\n",
    "    print('connected to redis on \"{}\", port {}'.format(ENV[current_env], port)) \n",
    "    return r\n",
    "\n",
    "def connect_to_mongo(port=27017):\n",
    "    if current_env == 'docker':\n",
    "        client = MongoClient(host=ENV[current_env],port=port, connectTimeoutMS=10000)\n",
    "        # client.admin.command('ping') # try to ping mongo server\n",
    "        print('connected to MongoDB on \"{}\", port {}'.format(ENV[current_env], port))\n",
    "    \n",
    "    elif current_env == 'production':\n",
    "        client = MongoClient()\n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mongo(client):\n",
    "    db = client[current_user]\n",
    "    companies = db.companies\n",
    "    print(\"companies collection created in {} db\".format(current_user))\n",
    "    return db, companies\n",
    "\n",
    "def reset_redis(r):\n",
    "    r.flushdb()\n",
    "    print('redis database number {} is clean'.format(redis_db_num))\n",
    "\n",
    "def reset_mongo(client):\n",
    "    client[current_user].companies.drop()\n",
    "    print(\"mongo is clean\")\n",
    "\n",
    "def restart():\n",
    "    # connect to dbs\n",
    "    r = connect_to_redis()\n",
    "    client = connect_to_mongo()\n",
    "    # clean dbs\n",
    "    reset_redis(r)\n",
    "    reset_mongo(client)\n",
    "    # setup the databases\n",
    "    db, companies = setup_mongo(client)\n",
    "    print(\"restart completed\")\n",
    "    return r, client, db, companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 1 - Add a new company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_company_exists(r, companies, company_name):\n",
    "    # check if company name in comapny set on redis\n",
    "    if r.sismember(companiesSet, company_name):\n",
    "        return True\n",
    "    \n",
    "    # if not, verify against mongo\n",
    "    elif companies.find_one({\"company_name\": company_name}) is not None:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def add_company(company_dict,r=None, companies=None):\n",
    "    if r is None:\n",
    "        r = connect_to_redis()\n",
    "    if companies is None:\n",
    "        companies = connect_to_mongo()[current_user].companies\n",
    "        \n",
    "    # getting dict for the company and insert it to db\n",
    "    if 'company_name' not in company_dict:\n",
    "        # raise ValueError(\"company dict must have company_name field\") #no errors allowed\n",
    "        print(\"company dict must have company_name field, no changes were commited to db\")\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        company_name = company_dict['company_name']\n",
    "    \n",
    "    # verify that company name is unique\n",
    "    if(is_company_exists(r, companies, company_name)):\n",
    "        # raise ValueError(\"company name already taken\") #no errors allowed\n",
    "        print(\"company name already taken, no changes were commited to db\")\n",
    "        return None\n",
    "        \n",
    "    # and then insert to mongo and redis\n",
    "    company_dict['jobs_list'] = [] # initiate jobs list\n",
    "    companies.insert_one(company_dict)\n",
    "    r.sadd(companiesSet, company_dict['company_name'])\n",
    "    print(\"%s Added successfully!\"%(company_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 2 - Add a new job position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_job_id(companies, company_name):\n",
    "    match = {'$match' : {'company_name':company_name}}\n",
    "    project = {'$project': { 'max_id': { '$size':'$jobs_list' }}}\n",
    "    res = companies.aggregate([match,project])\n",
    "    return list(res)[0]['max_id'] + 1\n",
    "\n",
    "def add_job(job_dict, company_name, r=None, companies=None):\n",
    "    # ASSUMPTION: there is no option to delete jobs (so counting jobs can be used to generate job id)\n",
    "    if r is None:\n",
    "        r = connect_to_redis()\n",
    "    if companies is None:\n",
    "        companies = connect_to_mongo()[current_user].companies\n",
    "    if not (is_company_exists(r, companies, company_name)):\n",
    "        raise ValueError(\"company doesn't exist\")\n",
    "    \n",
    "    # generate job id and insert to the company object\n",
    "    job_dict['job_id'] = generate_job_id(companies, company_name)\n",
    "    job_dict['application_list'] = [] # initiate application list\n",
    "    companies.update_one({'company_name': company_name}, {'$push': {'jobs_list': job_dict}}, upsert = True)\n",
    "    r.zincrby(ojOSet,\"%s:%s\"%(job_dict['location'],job_dict['job_title']),amount=1)\n",
    "    print(\"job with id %s was added to %s jobs successfully!\"%(job_dict['job_id'], company_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 3 - Add a new application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_job_open(companies, company_name, job_id):\n",
    "    res = companies.find_one(\n",
    "        { \n",
    "            \"company_name\": company_name,\n",
    "        },\n",
    "        { \"jobs_list\": { \"$elemMatch\": { \"job_id\": int(job_id), \"status\": \"open\" }}}\n",
    "    )\n",
    "    return('jobs_list' in res)\n",
    "\n",
    "def is_already_submitted(companies, company_name, job_id, email):\n",
    "    res = companies.find_one(\n",
    "        { \n",
    "            \"company_name\": company_name,\n",
    "        },\n",
    "        { \"jobs_list\": { \"$elemMatch\": { \"job_id\": int(job_id), \"application_list\": {\"$elemMatch\": {'email':email}} }}}\n",
    "    )\n",
    "    return('jobs_list' in res) # if mail doesn't exists an empty object will returned\n",
    "\n",
    "def new_application(candidate, application_time, job_id, company_name, r=None, companies=None):\n",
    "    if r is None:\n",
    "        r = connect_to_redis()\n",
    "    if companies is None:\n",
    "        companies = connect_to_mongo()[current_user].companies\n",
    "\n",
    "    if (not is_job_open(companies, company_name, job_id)):\n",
    "        print(\"you are trying to apply to a closed job\")\n",
    "        return -1\n",
    "\n",
    "    if (is_already_submitted(companies, company_name, job_id, candidate['email'])):\n",
    "        print(\"you have already sent application for this job\")\n",
    "        return -2\n",
    "\n",
    "    # update in mongo\n",
    "    d = datetime.datetime.strptime(application_time, \"%d-%m-%Y %H:%M:%S\")\n",
    "    candidate['application_date'] = d\n",
    "    companies.update_one({\"company_name\": company_name,\"jobs_list\": {\"$elemMatch\":{\"job_id\":int(job_id)}}},{'$push':{'jobs_list.$.application_list':candidate}})\n",
    "\n",
    "    #update in redis\n",
    "    unix_d = time.mktime(d.timetuple())\n",
    "    #check if company already exists in redis\n",
    "    key_string = \"candidate_applications:{}\".format(candidate['email'])\n",
    "    comps = r.zrange(key_string,0,-1,withscores=True)\n",
    "    comp = [x for x in comps if x[0]==company_name]\n",
    "    # if comany already exists - change vlaue to most recent date\n",
    "    if len(comp)>0:\n",
    "        old_timestamp = comp[0][1]\n",
    "        if unix_d>old_timestamp:\n",
    "            r.zadd(key_string,unix_d,company_name)\n",
    "    else:\n",
    "        r.zadd(key_string,unix_d,company_name)\n",
    "        \n",
    "    print(\"{} submited application for job number {} at {}\".format(candidate['candidate_name'],job_id, company_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 4 - Update job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_job_status(company_name, job_id, new_status, r=None, companies=None):\n",
    "    #TODO: update open jobs on redis\n",
    "    if r is None:\n",
    "        r = connect_to_redis()\n",
    "    if companies is None:\n",
    "        companies = connect_to_mongo()[current_user].companies\n",
    "    \n",
    "    companies.update_one({\"company_name\": company_name,\"jobs_list\": {\"$elemMatch\":{\"job_id\":int(job_id)}}},{'$set':{'jobs_list.$.status':new_status}})\n",
    "    print(\"job number: {} at {} is now: {}\".format(job_id, company_name, new_status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 5 - show latest companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_latest_10_companies(candidate_email):\n",
    "    key_string = \"candidate_applications:{}\".format(candidate_email)\n",
    "    return r.zrevrange(key_string, 0, 9, withscores=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 6 - show number of open jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_number_of_jobs(location,title):\n",
    "    key_string = \"%s:%s\"%(location,title)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to redis on \"bdl1.eng.tau.ac.il\", port 6379\n",
      "redis database number 10 is clean\n",
      "mongo is clean\n",
      "companies collection created in stud10 db\n"
     ]
    }
   ],
   "source": [
    "r = connect_to_redis(redis_db_num)\n",
    "client = connect_to_mongo()\n",
    "\n",
    "# clean the databases\n",
    "reset_redis(r)\n",
    "reset_mongo(client)\n",
    "\n",
    "# setup the databases\n",
    "db, companies = setup_mongo(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAU Added successfully!\n"
     ]
    }
   ],
   "source": [
    "# Operation 1 - Add a new company\n",
    "add_company({'company_name':'TAU', 'company_description':'University'}, r=r, companies=companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job with id 1 was added to TAU jobs successfully!\n"
     ]
    }
   ],
   "source": [
    "# Operation 2 - Add a new job position\n",
    "add_job({'job_title':'bi developer', 'location': 'Tel Aviv','requirements':['python','big data','mongodb'],'status':'open','publish_date':'01-02-2020'},'TAU', r=r, companies=companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have already sent application for this job\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Operation 3 - Add a new application\n",
    "new_application({'candidate_name':'laura', 'email':'laura@gmail.com','linkedin':'https://www.linkedin.com/in/laura/', 'skills': ['python','sql']},'01-02-2020 15:00:00', '1','TAU', r=r, companies=companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job number: 1 at TAU is now: open\n"
     ]
    }
   ],
   "source": [
    "# Operation 4 - Update job status\n",
    "update_job_status('TAU','1','open', r=r, companies=companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': ObjectId('6252ade88ec14341988330d8'),\n",
       "  u'company_description': u'University',\n",
       "  u'company_name': u'TAU',\n",
       "  u'jobs_list': [{u'application_list': [{u'application_date': datetime.datetime(2020, 2, 1, 15, 0),\n",
       "      u'candidate_name': u'laura',\n",
       "      u'email': u'laura@gmail.com',\n",
       "      u'linkedin': u'https://www.linkedin.com/in/laura/',\n",
       "      u'skills': [u'python', u'sql']}],\n",
       "    u'job_id': 1,\n",
       "    u'job_title': u'bi developer',\n",
       "    u'location': u'Tel Aviv',\n",
       "    u'publish_date': u'01-02-2020',\n",
       "    u'requirements': [u'python', u'big data', u'mongodb'],\n",
       "    u'status': u'open'}]}]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db['companies'].find({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': ObjectId('6252ade88ec14341988330d8'), u'max_id': 1}]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = {'$match' : {'company_name':'TAU'}}\n",
    "project = {'$project': { 'max_id': { '$size':'$jobs_list' }}}\n",
    "# project = {'$project': { 'count': { '$size':'$jobs_list' }}}\n",
    "res = companies.aggregate([match,project])\n",
    "list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "Unrecognized parameter to $cond: status",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationFailure\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-a9aa94a41ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \"open_jobs\": {\"$sum\": 1}}}\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompanies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munwind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, pipeline, session, **kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m                                    \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m                                    \u001b[0mexplicit_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m                                    **kwargs)\n\u001b[0m\u001b[1;32m   2398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maggregate_raw_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, pipeline, cursor_class, first_batch_size, session, explicit_session, **kwargs)\u001b[0m\n\u001b[1;32m   2302\u001b[0m                 \u001b[0mcollation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2303\u001b[0m                 \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2304\u001b[0;31m                 client=self.__database.client)\n\u001b[0m\u001b[1;32m   2305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"cursor\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pymongo/pool.pyc\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events)\u001b[0m\n\u001b[1;32m    577\u001b[0m                            \u001b[0mcompression_ctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                            \u001b[0muse_op_msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_msg_enabled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                            unacknowledged=unacknowledged)\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pymongo/network.pyc\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(sock, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 helpers._check_command_response(\n\u001b[1;32m    149\u001b[0m                     \u001b[0mresponse_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowable_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                     parse_write_concern_error=parse_write_concern_error)\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpublish\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pymongo/helpers.pyc\u001b[0m in \u001b[0;36m_check_command_response\u001b[0;34m(response, msg, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationFailure\u001b[0m: Unrecognized parameter to $cond: status"
     ]
    }
   ],
   "source": [
    "unwind = {\"$unwind\": \"$jobs_list\"}\n",
    "project = {\"$project\":{\n",
    "            'open_jobs':{\n",
    "                \"$cond\": {\"jobs_list.status\":{\"$eq\":\"open\"}}\n",
    "                },\n",
    "            'closed_jobs':{\n",
    "                \"$cond\": {\"jobs_list.status\":{\"$eq\":\"close\"}}\n",
    "            }\n",
    "    }\n",
    "}\n",
    "group = { \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"publish_date\":\"$jobs_list.publish_date\",\n",
    "                \"company_name\": \"$company_name\"\n",
    "                },\n",
    "            \"open_jobs\": {\"$sum\": 1}}}\n",
    "\n",
    "res = companies.aggregate([unwind, project, group])\n",
    "list(res)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'storageEngines': [u'devnull', u'ephemeralForTest', u'mmapv1', u'wiredTiger'], u'maxBsonObjectSize': 16777216, u'ok': 1.0, u'bits': 64, u'modules': [], u'openssl': {u'compiled': u'OpenSSL 1.0.1e-fips 11 Feb 2013', u'running': u'OpenSSL 1.0.1e-fips 11 Feb 2013'}, u'javascriptEngine': u'mozjs', u'version': u'3.4.18', u'gitVersion': u'4410706bef6463369ea2f42399e9843903b31923', u'versionArray': [3, 4, 18, 0], u'debug': False, u'buildEnvironment': {u'cxxflags': u'-Woverloaded-virtual -Wno-maybe-uninitialized -std=c++11', u'cc': u'/opt/mongodbtoolchain/v2/bin/gcc: gcc (GCC) 5.4.0', u'linkflags': u'-pthread -Wl,-z,now -rdynamic -Wl,--fatal-warnings -fstack-protector-strong -fuse-ld=gold -Wl,--build-id -Wl,-z,noexecstack -Wl,--warn-execstack -Wl,-z,relro', u'distarch': u'x86_64', u'cxx': u'/opt/mongodbtoolchain/v2/bin/g++: g++ (GCC) 5.4.0', u'ccflags': u'-fno-omit-frame-pointer -fno-strict-aliasing -ggdb -pthread -Wall -Wsign-compare -Wno-unknown-pragmas -Winvalid-pch -Werror -O2 -Wno-unused-local-typedefs -Wno-unused-function -Wno-deprecated-declarations -Wno-unused-but-set-variable -Wno-missing-braces -fstack-protector-strong -fno-builtin-memcmp', u'target_arch': u'x86_64', u'distmod': u'rhel70', u'target_os': u'linux'}, u'sysInfo': u'deprecated', u'allocator': u'tcmalloc'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.server_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'01-02-2020', u'open_jobs': 3}]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = companies.aggregate([\n",
    "    { \"$unwind\": \"$jobs_list\"},\n",
    "    { \"$match\": {\"jobs_list.status\": \"open\"} },\n",
    "    { \"$group\": {\"_id\": \"$jobs_list.publish_date\", \"open_jobs\": {\"$sum\": 1}}}\n",
    "    ])\n",
    "list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laura submited application for job number 3 at TAU\n"
     ]
    }
   ],
   "source": [
    "new_application({'candidate_name':'laura', 'email':'laura@gmail.com','linkedin':'https://www.linkedin.com/in/laura/', 'skills': ['python','sql']},'14-02-2022 15:00:00', '3','TAU', r=r, companies=companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TAU', 1644843600.0)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.zrange('candidate_applications:laura@gmail.com',0,-1,withscores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = r.zrange('moti:luhim',0,-1,withscores=True)\n",
    "b = [x for x in a if x[0]=='haim']\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.keys('stud10:')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
